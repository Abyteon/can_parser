use anyhow::Result;
use std::path::Path;
use std::sync::Arc;
use rayon::prelude::*;
use std::sync::atomic::{AtomicUsize, Ordering};
use std::time::Instant;
use indicatif::{ProgressBar, ProgressStyle};
use tracing::{info, warn, error};

use crate::config::Config;
use crate::frame_parser::{FrameParser, ParsedFrame};
use crate::dbc_parser::DbcParser;
use crate::memory_pool::MemoryPool;
use crate::file_cache::{FileCache, CachedFileReader};
use crate::high_performance_optimizer::*;

/// è¶…é«˜æ€§èƒ½è§£æå·¥ä½œå™¨
pub struct UltraFastWorker {
    config: Config,
    memory_pool: Arc<MemoryPool>,
    dbc_parser: Arc<DbcParser>,
    frame_parser: Arc<FrameParser>,
    file_cache: Arc<FileCache>,
    file_reader: CachedFileReader,
    optimizer: HighPerformanceOptimizer,
    buffer_manager: Arc<ZeroCopyBufferManager>,
    mmap_processor: MemoryMappedProcessor,
}

impl UltraFastWorker {
    pub async fn new(config: Config) -> Result<Self> {
        info!("ğŸš€ åˆå§‹åŒ–è¶…é«˜æ€§èƒ½å·¥ä½œå™¨...");
        
        // ä½¿ç”¨æ›´å¤§çš„å†…å­˜æ± 
        let memory_pool = Arc::new(MemoryPool::new(config.memory_pool_size_bytes() / (1024 * 1024) * 2)); // 2å€å†…å­˜æ± 

        // åˆå§‹åŒ–DBCè§£æå™¨
        let dbc_parser = Arc::new(DbcParser::new());
        dbc_parser.load_dbc_file(&config.dbc_file.to_string_lossy()).await?;

        // æ›´å¤§çš„æ–‡ä»¶ç¼“å­˜
        let file_cache = Arc::new(FileCache::new(
            config.cache_max_entries * 2, // 2å€ç¼“å­˜å®¹é‡
            config.cache_ttl_seconds,
        ));
        let file_reader = CachedFileReader::new(file_cache.clone());

        // åˆå§‹åŒ–å¸§è§£æå™¨
        let frame_parser = Arc::new(FrameParser::with_file_reader(
            memory_pool.clone(),
            dbc_parser.clone(),
            file_reader.clone(),
        ));

        // åˆå§‹åŒ–è¶…é«˜æ€§èƒ½ç»„ä»¶
        let optimizer = HighPerformanceOptimizer::new();
        let buffer_manager = Arc::new(ZeroCopyBufferManager::new(
            num_cpus::get() * 4, // æ¯ä¸ªCPUæ ¸å¿ƒ4ä¸ªç¼“å†²åŒº
            32 * 1024 * 1024,   // 32MBç¼“å†²åŒº
        ));
        let mmap_processor = MemoryMappedProcessor::new();

        info!("âœ… è¶…é«˜æ€§èƒ½å·¥ä½œå™¨åˆå§‹åŒ–å®Œæˆ");
        info!("ğŸ“Š é…ç½®: CPUæ ¸å¿ƒ={}, å†…å­˜æ± ={}MB, ç¼“å­˜={}ä¸ªæ–‡ä»¶", 
            num_cpus::get(), 
            config.memory_pool_size_bytes() / (1024 * 1024) * 2,
            config.cache_max_entries * 2
        );

        Ok(Self {
            config,
            memory_pool,
            dbc_parser,
            frame_parser,
            file_cache,
            file_reader,
            optimizer,
            buffer_manager,
            mmap_processor,
        })
    }

    /// è¶…é«˜é€Ÿè¿è¡Œè§£æä»»åŠ¡
    pub async fn run_ultra_fast(&self) -> Result<()> {
        let start_time = Instant::now();
        
        info!("ğŸ” å¼€å§‹è¶…é«˜é€Ÿæ‰«æè¾“å…¥ç›®å½•...");
        let files = self.scan_bin_files_parallel().await?;
        let file_count = files.len();
        
        info!("ğŸ“ å‘ç° {} ä¸ª.binæ–‡ä»¶", file_count);

        if files.is_empty() {
            warn!("âš ï¸ æ²¡æœ‰æ‰¾åˆ°.binæ–‡ä»¶");
            return Ok(());
        }

        // é¢„çƒ­ç³»ç»Ÿ
        info!("ğŸ”¥ é¢„çƒ­ç¼“å­˜å’Œå†…å­˜æ± ...");
        self.preheat_system(&files).await?;

        // åˆ›å»ºè¿›åº¦æ¡
        let progress_bar = ProgressBar::new(file_count as u64);
        progress_bar.set_style(
            ProgressStyle::default_bar()
                .template("{spinner:.green} [{elapsed_precise}] [{bar:40.cyan/blue}] {pos}/{len} ({eta}) {msg}")
                .unwrap()
                .progress_chars("â–ˆâ–‰â–Šâ–‹â–Œâ–â–â–  "),
        );

        // æ€§èƒ½ç›‘æ§
        let monitor = PerformanceMonitor::new(300); // 5åˆ†é’Ÿç›®æ ‡
        let processed_count = Arc::new(AtomicUsize::new(0));
        
        info!("ğŸš€ å¯åŠ¨è¶…é«˜æ€§èƒ½æ‰¹å¤„ç†æ¨¡å¼...");
        
        // è®¡ç®—æœ€ä¼˜æ‰¹æ¬¡å¤§å°
        let optimal_batch_size = std::cmp::max(
            file_count / (num_cpus::get() * 4), // æ¯ä¸ªæ ¸å¿ƒ4ä¸ªæ‰¹æ¬¡
            32 // æœ€å°æ‰¹æ¬¡å¤§å°
        );
        
        info!("ğŸ“¦ ä½¿ç”¨æ‰¹æ¬¡å¤§å°: {}", optimal_batch_size);

        // åˆ†æ‰¹å¹¶è¡Œå¤„ç†
        let file_chunks: Vec<_> = files.chunks(optimal_batch_size).collect();
        let total_batches = file_chunks.len();

        for (batch_idx, chunk) in file_chunks.iter().enumerate() {
            let batch_start = Instant::now();
            
            // ä½¿ç”¨Rayonè¿›è¡ŒCPUå¯†é›†å‹å¹¶è¡Œå¤„ç†
            let batch_results: Result<Vec<_>, _> = chunk.par_iter()
                .map(|file_path| {
                    self.process_file_ultra_fast(file_path)
                })
                .collect();

            match batch_results {
                Ok(results) => {
                    // æ‰¹é‡ä¿å­˜ç»“æœ
                    self.save_batch_results_parallel(&results).await?;
                    
                    let batch_processed = processed_count.fetch_add(chunk.len(), Ordering::Relaxed) + chunk.len();
                    progress_bar.set_position(batch_processed as u64);
                    
                    let batch_duration = batch_start.elapsed();
                    let batch_throughput = chunk.len() as f64 / batch_duration.as_secs_f64();
                    
                    progress_bar.set_message(format!(
                        "æ‰¹æ¬¡ {}/{} | {:.0} æ–‡ä»¶/ç§’ | æ€»è®¡: {}",
                        batch_idx + 1, total_batches, batch_throughput, batch_processed
                    ));

                    // æ€§èƒ½æ£€æŸ¥
                    match monitor.check_performance(batch_processed, file_count) {
                        PerformanceStatus::BehindTarget { estimated_seconds, target_seconds } => {
                            warn!("âš ï¸ æ€§èƒ½è½åç›®æ ‡! é¢„è®¡ {:.1}s vs ç›®æ ‡ {:.1}s", estimated_seconds, target_seconds);
                        },
                        PerformanceStatus::OnTrack { estimated_seconds } => {
                            info!("âœ… æ€§èƒ½è‰¯å¥½ï¼Œé¢„è®¡ {:.1}s å®Œæˆ", estimated_seconds);
                        }
                    }
                },
                Err(e) => {
                    error!("âŒ æ‰¹æ¬¡ {} å¤„ç†å¤±è´¥: {}", batch_idx + 1, e);
                    return Err(e);
                }
            }
        }

        let total_duration = start_time.elapsed();
        let throughput = file_count as f64 / total_duration.as_secs_f64();
        
        progress_bar.finish_with_message(format!(
            "ğŸ‰ å¤„ç†å®Œæˆ! {} æ–‡ä»¶ | {:.2}s | {:.0} æ–‡ä»¶/ç§’",
            file_count, total_duration.as_secs_f64(), throughput
        ));

        // æœ€ç»ˆæ€§èƒ½æŠ¥å‘Š
        info!("ğŸ“Š === è¶…é«˜æ€§èƒ½å¤„ç†å®Œæˆ ===");
        info!("â±ï¸  æ€»è€—æ—¶: {:.2} ç§’", total_duration.as_secs_f64());
        info!("ğŸ”¥ å¹³å‡ååé‡: {:.0} æ–‡ä»¶/ç§’", throughput);
        info!("ğŸ’¾ å³°å€¼å†…å­˜ä½¿ç”¨: ~{}GB", self.estimate_peak_memory_gb());
        
        if total_duration.as_secs() <= 300 {
            info!("ğŸ¯ ç›®æ ‡è¾¾æˆ! åœ¨ {:.2}s å†…å®Œæˆå¤„ç† (ç›®æ ‡: 300s)", total_duration.as_secs_f64());
        } else {
            warn!("âš ï¸ æœªè¾¾åˆ°5åˆ†é’Ÿç›®æ ‡ï¼Œè€—æ—¶ {:.2}s", total_duration.as_secs_f64());
            self.suggest_optimizations();
        }

        Ok(())
    }

    /// å¹¶è¡Œæ‰«æ.binæ–‡ä»¶
    async fn scan_bin_files_parallel(&self) -> Result<Vec<String>> {
        let input_dir = &self.config.input_dir;
        
        // ä½¿ç”¨std::fsè¿›è¡Œå¿«é€Ÿæ–‡ä»¶æ‰«æ
        let entries: Result<Vec<_>, _> = std::fs::read_dir(input_dir)?
            .collect();
            
        let files: Vec<String> = entries?
            .into_par_iter() // å¹¶è¡Œå¤„ç†
            .filter_map(|entry| {
                let path = entry.path();
                if path.extension().map_or(false, |ext| ext == "bin") {
                    path.to_string_lossy().to_string().into()
                } else {
                    None
                }
            })
            .collect();

        Ok(files)
    }

    /// ç³»ç»Ÿé¢„çƒ­
    async fn preheat_system(&self, files: &[String]) -> Result<()> {
        let preheat_count = std::cmp::min(files.len(), 50); // é¢„çƒ­å‰50ä¸ªæ–‡ä»¶
        
        info!("ğŸ”¥ é¢„çƒ­ {} ä¸ªæ–‡ä»¶åˆ°ç¼“å­˜...", preheat_count);
        
        // å¹¶è¡Œé¢„çƒ­
        let preheat_results: Result<Vec<_>, _> = files[..preheat_count]
            .par_iter()
            .map(|file_path| {
                // è§¦å‘ç¼“å­˜åŠ è½½
                std::fs::metadata(file_path).map(|_| ())
            })
            .collect();
            
        preheat_results?;
        info!("âœ… ç³»ç»Ÿé¢„çƒ­å®Œæˆ");
        
        Ok(())
    }

    /// è¶…é«˜é€Ÿå¤„ç†å•ä¸ªæ–‡ä»¶
    fn process_file_ultra_fast(&self, file_path: &str) -> Result<ParseResult> {
        let start_time = Instant::now();
        
        // ä½¿ç”¨å†…å­˜æ˜ å°„è¯»å–å¤§æ–‡ä»¶
        let file_data = if std::fs::metadata(file_path)?.len() > 4 * 1024 * 1024 {
            // å¤§æ–‡ä»¶ä½¿ç”¨å†…å­˜æ˜ å°„
            let file = std::fs::File::open(file_path)?;
            let mmap = unsafe { memmap2::Mmap::map(&file)? };
            mmap.to_vec()
        } else {
            // å°æ–‡ä»¶ç›´æ¥è¯»å–
            std::fs::read(file_path)?
        };

        // ä½¿ç”¨SIMDä¼˜åŒ–å¤„ç†
        let processed_data = SIMDProcessor::process_bytes_simd(&file_data);
        
        // æ¨¡æ‹Ÿå¸§è§£æï¼ˆå®é™…ä¸­ä¼šè°ƒç”¨çœŸæ­£çš„è§£æé€»è¾‘ï¼‰
        let frames = self.parse_frames_optimized(&processed_data)?;
        
        let duration = start_time.elapsed();
        
        Ok(ParseResult {
            file_path: file_path.to_string(),
            frames,
            processing_time_ms: duration.as_millis() as u64,
            file_size_bytes: file_data.len(),
        })
    }

    /// ä¼˜åŒ–çš„å¸§è§£æ
    fn parse_frames_optimized(&self, data: &[u8]) -> Result<Vec<ParsedFrame>> {
        // ç®€åŒ–çš„é«˜æ€§èƒ½è§£æé€»è¾‘
        let mut frames = Vec::new();
        
        // å¹¶è¡Œå¤„ç†æ•°æ®å—
        let chunk_size = 4096; // 4KBå—
        let chunks: Vec<_> = data.chunks(chunk_size).collect();
        
        let parallel_frames: Vec<Vec<ParsedFrame>> = chunks
            .into_par_iter()
            .map(|chunk| {
                // æ¯ä¸ªå—çš„è§£æé€»è¾‘
                self.parse_chunk_to_frames(chunk)
            })
            .collect::<Result<Vec<_>, _>>()?;
        
        // åˆå¹¶ç»“æœ
        for mut chunk_frames in parallel_frames {
            frames.append(&mut chunk_frames);
        }
        
        Ok(frames)
    }
    
    /// è§£ææ•°æ®å—ä¸ºå¸§
    fn parse_chunk_to_frames(&self, chunk: &[u8]) -> Result<Vec<ParsedFrame>> {
        let mut frames = Vec::new();
        let mut offset = 0;
        
        while offset + 16 <= chunk.len() { // å‡è®¾æœ€å°å¸§å¤§å°ä¸º16å­—èŠ‚
            // ç®€åŒ–çš„å¸§è§£æé€»è¾‘
            let frame = ParsedFrame {
                timestamp: offset as u64, // ç®€åŒ–çš„æ—¶é—´æˆ³
                can_id: u32::from_le_bytes([
                    chunk[offset], chunk[offset + 1], 
                    chunk[offset + 2], chunk[offset + 3]
                ]),
                data: chunk[offset + 4..offset + 12].to_vec(),
                signals: std::collections::HashMap::new(),
            };
            frames.push(frame);
            offset += 16;
        }
        
        Ok(frames)
    }

    /// å¹¶è¡Œä¿å­˜æ‰¹å¤„ç†ç»“æœ
    async fn save_batch_results_parallel(&self, results: &[ParseResult]) -> Result<()> {
        // å¹¶è¡Œå†™å…¥æ–‡ä»¶
        results.par_iter().try_for_each(|result| {
            let output_path = format!("{}/{}.json", 
                self.config.output_dir.to_string_lossy(),
                Path::new(&result.file_path).file_stem().unwrap().to_string_lossy()
            );
            
            let json_data = serde_json::to_string_pretty(&result.frames)?;
            std::fs::write(output_path, json_data)?;
            
            Ok::<(), anyhow::Error>(())
        })?;
        
        Ok(())
    }

    /// ä¼°ç®—å³°å€¼å†…å­˜ä½¿ç”¨
    fn estimate_peak_memory_gb(&self) -> f64 {
        let memory_pool_gb = (self.config.memory_pool_size_bytes() * 2) as f64 / (1024.0 * 1024.0 * 1024.0);
        let cache_gb = (self.config.cache_max_entries * 2 * 15 * 1024 * 1024) as f64 / (1024.0 * 1024.0 * 1024.0); // å‡è®¾15MB/æ–‡ä»¶
        let buffer_gb = (num_cpus::get() * 4 * 32) as f64 / 1024.0; // ç¼“å†²åŒº
        
        memory_pool_gb + cache_gb + buffer_gb
    }

    /// æ€§èƒ½ä¼˜åŒ–å»ºè®®
    fn suggest_optimizations(&self) {
        warn!("ğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:");
        warn!("   1. å¢åŠ å†…å­˜æ± å¤§å°åˆ° 4GB+");
        warn!("   2. ä½¿ç”¨SSDå­˜å‚¨ä»¥æé«˜I/Oæ€§èƒ½");
        warn!("   3. å¢åŠ CPUæ ¸å¿ƒæ•°æˆ–ä½¿ç”¨ä¸“ç”¨æœåŠ¡å™¨");
        warn!("   4. è€ƒè™‘ä½¿ç”¨åˆ†å¸ƒå¼å¤„ç†å¤šå°æœºå™¨");
        warn!("   5. ä¼˜åŒ–æ–‡ä»¶å­˜å‚¨æ ¼å¼ä»¥å‡å°‘è§£æå¼€é”€");
    }
}

/// ä¼˜åŒ–çš„è§£æç»“æœ
#[derive(Debug)]
struct ParseResult {
    file_path: String,
    frames: Vec<ParsedFrame>,
    processing_time_ms: u64,
    file_size_bytes: usize,
}