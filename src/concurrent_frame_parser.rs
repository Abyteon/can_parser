use anyhow::{Result, anyhow};
use std::sync::Arc;
use rayon::prelude::*;
use tokio::task;
use tracing::{info, debug};

use crate::frame_parser::{ParsedFrame, FileLevelData};
use crate::memory_pool::MemoryPool;
use crate::dbc_parser::DbcParser;
use crate::file_cache::CachedFileReader;

/// å¹¶å‘å¢å¼ºçš„å¸§è§£æå™¨ - åœ¨æ¯ä¸€å±‚éƒ½ä½¿ç”¨å¹¶å‘å¤„ç†
pub struct ConcurrentFrameParser {
    memory_pool: Arc<MemoryPool>,
    dbc_parser: Arc<DbcParser>,
    file_reader: Option<CachedFileReader>,
    config: ConcurrentParseConfig,
}

/// å¹¶å‘è§£æé…ç½®
#[derive(Debug, Clone)]
pub struct ConcurrentParseConfig {
    /// è§£å‹ç¼©å¹¶å‘æ•°
    pub decompress_workers: usize,
    /// è§£æå±‚çº§å¹¶å‘æ•°  
    pub parse_workers: usize,
    /// å¸§å¤„ç†å¹¶å‘æ•°
    pub frame_workers: usize,
    /// æ‰¹å¤„ç†å¤§å°
    pub batch_size: usize,
}

impl Default for ConcurrentParseConfig {
    fn default() -> Self {
        let cpu_count = num_cpus::get();
        Self {
            decompress_workers: cpu_count,      // è§£å‹ç¼©CPUå¯†é›†
            parse_workers: cpu_count * 2,       // è§£æç›¸å¯¹è½»é‡
            frame_workers: cpu_count * 2,       // å¸§å¤„ç†å¹¶å‘
            batch_size: 64,                     // æ‰¹å¤„ç†å¤§å°
        }
    }
}

impl ConcurrentFrameParser {
    pub fn new(
        memory_pool: Arc<MemoryPool>, 
        dbc_parser: Arc<DbcParser>,
        file_reader: Option<CachedFileReader>,
        config: Option<ConcurrentParseConfig>
    ) -> Self {
        Self {
            memory_pool,
            dbc_parser,
            file_reader,
            config: config.unwrap_or_default(),
        }
    }

    /// å¹¶å‘è§£ææ–‡ä»¶ - ä¸»å…¥å£ç‚¹
    pub async fn parse_file_concurrent(&self, file_path: &str) -> Result<Vec<ParsedFrame>> {
        debug!("ğŸš€ å¼€å§‹å¹¶å‘è§£ææ–‡ä»¶: {}", file_path);
        
        // 1. è¯»å–æ–‡ä»¶æ•°æ®
        let file_data = self.read_file_data(file_path).await?;
        
        // 2. å¹¶å‘è§£æç¬¬0å±‚ - æ–‡ä»¶çº§åˆ«çš„å‹ç¼©æ•°æ®å—
        let compressed_blocks = self.parse_file_level_concurrent(&file_data).await?;
        debug!("ğŸ“¦ è§£æåˆ° {} ä¸ªå‹ç¼©æ•°æ®å—", compressed_blocks.len());
        
        // 3. å¹¶å‘è§£å‹ç¼©æ‰€æœ‰æ•°æ®å—
        let decompressed_blocks = self.decompress_blocks_concurrent(compressed_blocks).await?;
        debug!("ğŸ—œï¸  è§£å‹ç¼©å®Œæˆï¼Œå¾—åˆ° {} ä¸ªæ•°æ®å—", decompressed_blocks.len());
        
        // 4. å¹¶å‘è§£ææ‰€æœ‰å±‚çº§
        let all_frames = self.parse_all_layers_concurrent(decompressed_blocks).await?;
        
        info!("âœ… å¹¶å‘è§£æå®Œæˆï¼Œå…±è·å¾— {} ä¸ªå¸§", all_frames.len());
        Ok(all_frames)
    }

    /// è¯»å–æ–‡ä»¶æ•°æ®
    async fn read_file_data(&self, file_path: &str) -> Result<Vec<u8>> {
        if let Some(ref reader) = self.file_reader {
            if let Some(data) = reader.read_file(std::path::Path::new(file_path)).await? {
                Ok(data.to_vec())
            } else {
                Err(anyhow!("æ–‡ä»¶ä¸å­˜åœ¨: {}", file_path))
            }
        } else {
            Ok(tokio::fs::read(file_path).await?)
        }
    }

    /// å¹¶å‘è§£æç¬¬0å±‚ - æ–‡ä»¶çº§åˆ«æ•°æ®
    async fn parse_file_level_concurrent(&self, data: &[u8]) -> Result<Vec<FileLevelData>> {
        let mut _blocks: Vec<FileLevelData> = Vec::new();
        let mut offset = 0;

        // é¦–å…ˆé¡ºåºè§£æå‡ºæ‰€æœ‰å—çš„è¾¹ç•Œ
        let mut block_ranges = Vec::new();
        while offset < data.len() {
            if data.len() - offset < 35 {
                break;
            }
            
            // è¯»å–æ•°æ®é•¿åº¦
            let data_length = u32::from_be_bytes([
                data[offset + 31], data[offset + 32], 
                data[offset + 33], data[offset + 34]
            ]) as usize;
            
            if data.len() - offset < 35 + data_length {
                break;
            }
            
            block_ranges.push((offset, 35 + data_length));
            offset += 35 + data_length;
        }

        // å¹¶å‘è§£ææ¯ä¸ªå—
        let parsed_blocks: Result<Vec<_>, _> = block_ranges
            .into_par_iter()
            .map(|(start, length)| {
                self.parse_single_file_block(&data[start..start + length])
            })
            .collect();

        parsed_blocks
    }

    /// è§£æå•ä¸ªæ–‡ä»¶çº§åˆ«æ•°æ®å—
    fn parse_single_file_block(&self, data: &[u8]) -> Result<FileLevelData> {
        if data.len() < 35 {
            return Err(anyhow!("æ•°æ®é•¿åº¦ä¸è¶³"));
        }

        let mut header = [0u8; 35];
        header.copy_from_slice(&data[0..35]);

        let data_length = u32::from_be_bytes([
            data[31], data[32], data[33], data[34]
        ]);

        let compressed_data = data[35..].to_vec();

        Ok(FileLevelData {
            header,
            data_length,
            compressed_data,
        })
    }

    /// å¹¶å‘è§£å‹ç¼©æ‰€æœ‰æ•°æ®å—
    async fn decompress_blocks_concurrent(&self, blocks: Vec<FileLevelData>) -> Result<Vec<Vec<u8>>> {
        info!("ğŸ—œï¸  å¼€å§‹å¹¶å‘è§£å‹ç¼© {} ä¸ªæ•°æ®å—", blocks.len());
        
        // ä½¿ç”¨tokioå’Œrayonç»“åˆè¿›è¡Œå¹¶å‘è§£å‹ç¼©
        let decompressed_results: Result<Vec<_>, _> = task::spawn_blocking(move || {
            blocks
                .into_par_iter()
                .map(|block| {
                    Self::decompress_single_block_static(&block.compressed_data)
                })
                .collect()
        }).await?;

        decompressed_results
    }

    /// è§£å‹ç¼©å•ä¸ªæ•°æ®å—
    fn decompress_single_block_static(compressed_data: &[u8]) -> Result<Vec<u8>> {
        use flate2::read::GzDecoder;
        use std::io::Read;
        
        let mut decoder = GzDecoder::new(compressed_data);
        let mut decompressed = Vec::new();
        decoder.read_to_end(&mut decompressed)?;
        Ok(decompressed)
    }

    /// å¹¶å‘è§£ææ‰€æœ‰å±‚çº§
    async fn parse_all_layers_concurrent(&self, decompressed_blocks: Vec<Vec<u8>>) -> Result<Vec<ParsedFrame>> {
        info!("âš™ï¸  å¼€å§‹å¹¶å‘è§£æå¤šå±‚æ•°æ®ç»“æ„");
        
        // ä½¿ç”¨æµæ°´çº¿æ–¹å¼å¹¶å‘å¤„ç†å¤šä¸ªå±‚çº§
        let all_frames_futures: Vec<_> = decompressed_blocks
            .into_iter()
            .map(|block| {
                let dbc_parser = self.dbc_parser.clone();
                task::spawn(async move {
                    Self::parse_block_layers_concurrent(block, dbc_parser).await
                })
            })
            .collect();

        // ç­‰å¾…æ‰€æœ‰å¹¶å‘ä»»åŠ¡å®Œæˆ
        let mut all_frames = Vec::new();
        for future in all_frames_futures {
            let block_frames = future.await??;
            all_frames.extend(block_frames);
        }

        Ok(all_frames)
    }

    /// å¹¶å‘è§£æå•ä¸ªå—çš„æ‰€æœ‰å±‚çº§
    async fn parse_block_layers_concurrent(
        block_data: Vec<u8>, 
        dbc_parser: Arc<DbcParser>
    ) -> Result<Vec<ParsedFrame>> {
        
        // ç¬¬1å±‚ï¼šå¹¶å‘è§£æå¸§åºåˆ—
        let frame_sequences = Self::parse_frame_sequences_concurrent(&block_data).await?;
        
        // ç¬¬2å±‚ï¼šå¹¶å‘è§£æå¸§é›†åˆ
        let all_frame_data = Self::parse_frames_concurrent(frame_sequences).await?;
        
        // ç¬¬3å±‚ï¼šå¹¶å‘è§£æå•ä¸ªå¸§
        let parsed_frames = Self::parse_single_frames_concurrent(all_frame_data, dbc_parser).await?;
        
        Ok(parsed_frames)
    }

    /// å¹¶å‘è§£æç¬¬1å±‚ï¼šå¸§åºåˆ—æ•°æ®
    async fn parse_frame_sequences_concurrent(data: &[u8]) -> Result<Vec<Vec<u8>>> {
        // é¦–å…ˆæ‰¾åˆ°æ‰€æœ‰åºåˆ—çš„è¾¹ç•Œ
        let mut sequence_ranges = Vec::new();
        let mut offset = 0;

        while offset < data.len() {
            if data.len() - offset < 24 { // 20å­—èŠ‚header + 4å­—èŠ‚é•¿åº¦
                break;
            }

            let data_length = u32::from_be_bytes([
                data[offset + 20], data[offset + 21], 
                data[offset + 22], data[offset + 23]
            ]) as usize;

            if data.len() - offset < 24 + data_length {
                break;
            }

            sequence_ranges.push((offset + 24, data_length));
            offset += 24 + data_length;
        }

        // å¹¶å‘æå–æ‰€æœ‰åºåˆ—æ•°æ®
        let sequences: Vec<Vec<u8>> = sequence_ranges
            .into_par_iter()
            .map(|(start, length)| {
                data[start..start + length].to_vec()
            })
            .collect();

        Ok(sequences)
    }

    /// å¹¶å‘è§£æç¬¬2å±‚ï¼šå¸§é›†åˆæ•°æ®
    async fn parse_frames_concurrent(sequences: Vec<Vec<u8>>) -> Result<Vec<Vec<u8>>> {
        let frame_futures: Vec<_> = sequences
            .into_iter()
            .map(|sequence| {
                task::spawn_blocking(move || {
                    Self::parse_frames_from_sequence(sequence)
                })
            })
            .collect();

        let mut all_frames = Vec::new();
        for future in frame_futures {
            let frames = future.await??;
            all_frames.extend(frames);
        }

        Ok(all_frames)
    }

    /// ä»åºåˆ—ä¸­è§£æå¸§é›†åˆ
    fn parse_frames_from_sequence(sequence_data: Vec<u8>) -> Result<Vec<Vec<u8>>> {
        let mut frames = Vec::new();
        let mut offset = 0;

        while offset < sequence_data.len() {
            if sequence_data.len() - offset < 24 {
                break;
            }

            let data_length = u32::from_be_bytes([
                sequence_data[offset + 20], sequence_data[offset + 21], 
                sequence_data[offset + 22], sequence_data[offset + 23]
            ]) as usize;

            if sequence_data.len() - offset < 24 + data_length {
                break;
            }

            let frame_data = sequence_data[offset + 24..offset + 24 + data_length].to_vec();
            frames.push(frame_data);
            offset += 24 + data_length;
        }

        Ok(frames)
    }

    /// å¹¶å‘è§£æç¬¬3å±‚ï¼šå•ä¸ªå¸§
    async fn parse_single_frames_concurrent(
        frame_data_list: Vec<Vec<u8>>, 
        dbc_parser: Arc<DbcParser>
    ) -> Result<Vec<ParsedFrame>> {
        
        // åˆ†æ‰¹å¤„ç†ï¼Œé¿å…åˆ›å»ºè¿‡å¤šä»»åŠ¡
        let batch_size = 128;
        let mut all_frames = Vec::new();

        for batch in frame_data_list.chunks(batch_size) {
            let batch_futures: Vec<_> = batch
                .iter()
                .map(|frame_data| {
                    let dbc_parser = dbc_parser.clone();
                    let frame_data = frame_data.clone();
                    task::spawn_blocking(move || {
                        Self::parse_single_frame_sync(frame_data, dbc_parser)
                    })
                })
                .collect();

            // ç­‰å¾…å½“å‰æ‰¹æ¬¡å®Œæˆ
            for future in batch_futures {
                if let Ok(frame) = future.await? {
                    all_frames.push(frame);
                }
            }
        }

        Ok(all_frames)
    }

    /// åŒæ­¥è§£æå•ä¸ªå¸§ï¼ˆåœ¨blockingçº¿ç¨‹æ± ä¸­è¿è¡Œï¼‰
    fn parse_single_frame_sync(frame_data: Vec<u8>, _dbc_parser: Arc<DbcParser>) -> Result<ParsedFrame> {
        // ç®€åŒ–çš„å¸§è§£æé€»è¾‘
        if frame_data.len() < 16 {
            return Err(anyhow!("å¸§æ•°æ®é•¿åº¦ä¸è¶³"));
        }

        // æå–åŸºæœ¬ä¿¡æ¯
        let timestamp = u64::from_le_bytes([
            frame_data[0], frame_data[1], frame_data[2], frame_data[3],
            frame_data[4], frame_data[5], frame_data[6], frame_data[7],
        ]);

        let can_id = u32::from_le_bytes([
            frame_data[8], frame_data[9], frame_data[10], frame_data[11]
        ]);

        let data_len = std::cmp::min(8, frame_data.len() - 12);
        let data = frame_data[12..12 + data_len].to_vec();

        // ä½¿ç”¨DBCè§£æä¿¡å·ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        let signals = std::collections::HashMap::new(); // ç®€åŒ–å¤„ç†

        Ok(ParsedFrame {
            timestamp,
            can_id,
            data,
            signals,
        })
    }

    /// è·å–é…ç½®ä¿¡æ¯
    pub fn get_config(&self) -> &ConcurrentParseConfig {
        &self.config
    }

    /// æ€§èƒ½ç»Ÿè®¡
    pub async fn get_performance_stats(&self) -> ConcurrentParseStats {
        ConcurrentParseStats {
            decompress_workers: self.config.decompress_workers,
            parse_workers: self.config.parse_workers,
            frame_workers: self.config.frame_workers,
            batch_size: self.config.batch_size,
        }
    }
}

/// å¹¶å‘è§£ææ€§èƒ½ç»Ÿè®¡
#[derive(Debug, Clone)]
pub struct ConcurrentParseStats {
    pub decompress_workers: usize,
    pub parse_workers: usize,
    pub frame_workers: usize,
    pub batch_size: usize,
}

/// å¹¶å‘è§£æå™¨æ„å»ºå™¨
pub struct ConcurrentFrameParserBuilder {
    memory_pool: Option<Arc<MemoryPool>>,
    dbc_parser: Option<Arc<DbcParser>>,
    file_reader: Option<CachedFileReader>,
    config: ConcurrentParseConfig,
}

impl ConcurrentFrameParserBuilder {
    pub fn new() -> Self {
        Self {
            memory_pool: None,
            dbc_parser: None,
            file_reader: None,
            config: ConcurrentParseConfig::default(),
        }
    }

    pub fn memory_pool(mut self, pool: Arc<MemoryPool>) -> Self {
        self.memory_pool = Some(pool);
        self
    }

    pub fn dbc_parser(mut self, parser: Arc<DbcParser>) -> Self {
        self.dbc_parser = Some(parser);
        self
    }

    pub fn file_reader(mut self, reader: CachedFileReader) -> Self {
        self.file_reader = Some(reader);
        self
    }

    pub fn decompress_workers(mut self, count: usize) -> Self {
        self.config.decompress_workers = count;
        self
    }

    pub fn parse_workers(mut self, count: usize) -> Self {
        self.config.parse_workers = count;
        self
    }

    pub fn frame_workers(mut self, count: usize) -> Self {
        self.config.frame_workers = count;
        self
    }

    pub fn batch_size(mut self, size: usize) -> Self {
        self.config.batch_size = size;
        self
    }

    pub fn build(self) -> Result<ConcurrentFrameParser> {
        Ok(ConcurrentFrameParser::new(
            self.memory_pool.ok_or_else(|| anyhow!("Memory pool required"))?,
            self.dbc_parser.ok_or_else(|| anyhow!("DBC parser required"))?,
            self.file_reader,
            Some(self.config),
        ))
    }
}

impl Default for ConcurrentFrameParserBuilder {
    fn default() -> Self {
        Self::new()
    }
}