use anyhow::{Result, anyhow};
use std::sync::Arc;
use rayon::prelude::*;
use tokio::task;
use tracing::{info, debug, warn};
use std::time::Instant;

use crate::frame_parser::{ParsedFrame, FileLevelData};
use crate::memory_pool::MemoryPool;
use crate::dbc_parser::DbcParser;
use crate::file_cache::CachedFileReader;

/// æ‰¹å¤„ç†å¹¶å‘è§£æå™¨ - é’ˆå¯¹å°æ•°æ®å—ä¼˜åŒ–
pub struct BatchConcurrentParser {
    memory_pool: Arc<MemoryPool>,
    dbc_parser: Arc<DbcParser>,
    file_reader: Option<CachedFileReader>,
    config: BatchProcessConfig,
}

/// æ‰¹å¤„ç†é…ç½® - é’ˆå¯¹å°æ•°æ®å—ä¼˜åŒ–
#[derive(Debug, Clone)]
pub struct BatchProcessConfig {
    /// è§£å‹ç¼©æ‰¹å¤„ç†å¤§å°ï¼ˆä¸€æ¬¡å¤„ç†å¤šå°‘ä¸ªå‹ç¼©å—ï¼‰
    pub decompress_batch_size: usize,
    /// è§£ææ‰¹å¤„ç†å¤§å°ï¼ˆä¸€æ¬¡å¤„ç†å¤šå°‘ä¸ªæ•°æ®å—ï¼‰  
    pub parse_batch_size: usize,
    /// å¸§å¤„ç†æ‰¹å¤„ç†å¤§å°ï¼ˆä¸€æ¬¡å¤„ç†å¤šå°‘ä¸ªå¸§ï¼‰
    pub frame_batch_size: usize,
    /// å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°
    pub worker_threads: usize,
    /// å°æ•°æ®å—é˜ˆå€¼ï¼ˆå°äºæ­¤å€¼ä½¿ç”¨æ‰¹å¤„ç†ï¼‰
    pub small_block_threshold: usize,
}

impl Default for BatchProcessConfig {
    fn default() -> Self {
        let cpu_count = num_cpus::get();
        Self {
            // é’ˆå¯¹å°å‹ç¼©å—ï¼Œæ‰¹é‡å¤„ç†æé«˜æ•ˆç‡
            decompress_batch_size: 32,      // ä¸€æ¬¡è§£å‹32ä¸ªå°å—
            parse_batch_size: 64,           // ä¸€æ¬¡è§£æ64ä¸ªæ•°æ®å—
            frame_batch_size: 128,          // ä¸€æ¬¡å¤„ç†128ä¸ªå¸§
            worker_threads: cpu_count,
            small_block_threshold: 8192,    // 8KBä»¥ä¸‹è®¤ä¸ºæ˜¯å°å—
        }
    }
}

/// æ•°æ®å—æ‰¹æ¬¡
#[derive(Debug, Clone)]
pub struct DataBatch<T> {
    pub items: Vec<T>,
    pub batch_id: usize,
    pub estimated_total_size: usize,
}

impl<T> DataBatch<T> {
    pub fn new(items: Vec<T>, batch_id: usize) -> Self {
        Self {
            items,
            batch_id,
            estimated_total_size: 0,
        }
    }

    pub fn len(&self) -> usize {
        self.items.len()
    }

    pub fn is_empty(&self) -> bool {
        self.items.is_empty()
    }
}

impl BatchConcurrentParser {
    pub fn new(
        memory_pool: Arc<MemoryPool>, 
        dbc_parser: Arc<DbcParser>,
        file_reader: Option<CachedFileReader>,
        config: Option<BatchProcessConfig>
    ) -> Self {
        let config = config.unwrap_or_default();
        info!("ğŸ”§ æ‰¹å¤„ç†å¹¶å‘è§£æå™¨é…ç½®: è§£å‹æ‰¹æ¬¡={}, è§£ææ‰¹æ¬¡={}, å¸§æ‰¹æ¬¡={}", 
              config.decompress_batch_size, config.parse_batch_size, config.frame_batch_size);
        
        Self {
            memory_pool,
            dbc_parser,
            file_reader,
            config,
        }
    }

    /// æ‰¹å¤„ç†å¹¶å‘è§£ææ–‡ä»¶ - ä¸»å…¥å£ç‚¹
    pub async fn parse_file_batch_concurrent(&self, file_path: &str) -> Result<Vec<ParsedFrame>> {
        let start_time = Instant::now();
        debug!("ğŸš€ å¼€å§‹æ‰¹å¤„ç†å¹¶å‘è§£ææ–‡ä»¶: {}", file_path);
        
        // 1. è¯»å–æ–‡ä»¶æ•°æ®
        let file_data = self.read_file_data(file_path).await?;
        debug!("ğŸ“ æ–‡ä»¶å¤§å°: {} KB", file_data.len() / 1024);
        
        // 2. åˆ†ææ•°æ®ç»“æ„ï¼Œåˆ›å»ºæ‰¹æ¬¡
        let compressed_blocks = self.parse_file_level_fast(&file_data)?;
        let batches = self.create_smart_batches(compressed_blocks);
        debug!("ğŸ“¦ åˆ›å»º {} ä¸ªæ‰¹æ¬¡ï¼Œå¹³å‡æ‰¹æ¬¡å¤§å°: {:.1}", 
               batches.len(), 
               batches.iter().map(|b| b.len()).sum::<usize>() as f64 / batches.len() as f64);
        
        // 3. æ‰¹å¤„ç†å¹¶å‘è§£å‹ç¼©
        let decompressed_batches = self.decompress_batches_concurrent(batches).await?;
        debug!("ğŸ—œï¸  æ‰¹å¤„ç†è§£å‹ç¼©å®Œæˆ");
        
        // 4. æ‰¹å¤„ç†å¹¶å‘è§£æ
        let all_frames = self.parse_batches_concurrent(decompressed_batches).await?;
        
        let elapsed = start_time.elapsed();
        info!("âœ… æ‰¹å¤„ç†å¹¶å‘è§£æå®Œæˆ: {} ä¸ªå¸§, è€—æ—¶ {:.2}s, é€Ÿåº¦ {:.0} å¸§/ç§’", 
              all_frames.len(), elapsed.as_secs_f64(), all_frames.len() as f64 / elapsed.as_secs_f64());
        
        Ok(all_frames)
    }

    /// è¯»å–æ–‡ä»¶æ•°æ®
    async fn read_file_data(&self, file_path: &str) -> Result<Vec<u8>> {
        if let Some(ref reader) = self.file_reader {
            if let Some(data) = reader.read_file(std::path::Path::new(file_path)).await? {
                Ok(data.to_vec())
            } else {
                Err(anyhow!("æ–‡ä»¶ä¸å­˜åœ¨: {}", file_path))
            }
        } else {
            Ok(tokio::fs::read(file_path).await?)
        }
    }

    /// å¿«é€Ÿè§£ææ–‡ä»¶çº§åˆ«æ•°æ®ï¼ˆåªè§£æç»“æ„ï¼Œä¸å¤åˆ¶æ•°æ®ï¼‰
    fn parse_file_level_fast(&self, data: &[u8]) -> Result<Vec<FileLevelData>> {
        let mut blocks = Vec::new();
        let mut offset = 0;

        while offset < data.len() {
            if data.len() - offset < 35 {
                break;
            }
            
            // å¿«é€Ÿè¯»å–æ•°æ®é•¿åº¦
            let data_length = u32::from_be_bytes([
                data[offset + 31], data[offset + 32], 
                data[offset + 33], data[offset + 34]
            ]);
            
            if data.len() - offset < 35 + data_length as usize {
                break;
            }
            
            // å¿«é€Ÿåˆ›å»ºå—ä¿¡æ¯
            let mut header = [0u8; 35];
            header.copy_from_slice(&data[offset..offset + 35]);
            let compressed_data = data[offset + 35..offset + 35 + data_length as usize].to_vec();
            
            blocks.push(FileLevelData {
                header,
                data_length,
                compressed_data,
            });
            
            offset += 35 + data_length as usize;
        }

        debug!("ğŸ“Š è§£æå‡º {} ä¸ªå‹ç¼©å—", blocks.len());
        Ok(blocks)
    }

    /// åˆ›å»ºæ™ºèƒ½æ‰¹æ¬¡ - æ ¹æ®æ•°æ®å—å¤§å°ä¼˜åŒ–æ‰¹å¤„ç†
    fn create_smart_batches(&self, blocks: Vec<FileLevelData>) -> Vec<DataBatch<FileLevelData>> {
        let mut batches = Vec::new();
        let mut current_batch = Vec::new();
        let mut current_size = 0;
        let mut batch_id = 0;

        for block in blocks {
            let block_size = block.compressed_data.len();
            
            // æ ¹æ®å—å¤§å°å†³å®šæ‰¹æ¬¡ç­–ç•¥
            let should_start_new_batch = if block_size < self.config.small_block_threshold {
                // å°å—ï¼šæŒ‰æ•°é‡æ‰¹å¤„ç†
                current_batch.len() >= self.config.decompress_batch_size
            } else {
                // å¤§å—ï¼šæŒ‰å¤§å°æ‰¹å¤„ç†æˆ–å•ç‹¬å¤„ç†
                current_size + block_size > self.config.small_block_threshold * 2 || 
                current_batch.len() >= self.config.decompress_batch_size / 2
            };

            if should_start_new_batch && !current_batch.is_empty() {
                let mut batch = DataBatch::new(current_batch, batch_id);
                batch.estimated_total_size = current_size;
                batches.push(batch);
                current_batch = Vec::new();
                current_size = 0;
                batch_id += 1;
            }

            current_batch.push(block);
            current_size += block_size;
        }

        // å¤„ç†æœ€åä¸€ä¸ªæ‰¹æ¬¡
        if !current_batch.is_empty() {
            let mut batch = DataBatch::new(current_batch, batch_id);
            batch.estimated_total_size = current_size;
            batches.push(batch);
        }

        debug!("ğŸ¯ æ‰¹æ¬¡ç»Ÿè®¡:");
        for (i, batch) in batches.iter().enumerate() {
            debug!("  æ‰¹æ¬¡{}: {} ä¸ªå—, æ€»å¤§å°: {} KB", 
                   i, batch.len(), batch.estimated_total_size / 1024);
        }

        batches
    }

    /// æ‰¹å¤„ç†å¹¶å‘è§£å‹ç¼©
    async fn decompress_batches_concurrent(&self, batches: Vec<DataBatch<FileLevelData>>) -> Result<Vec<DataBatch<Vec<u8>>>> {
        info!("ğŸ—œï¸  å¼€å§‹æ‰¹å¤„ç†å¹¶å‘è§£å‹ç¼© {} ä¸ªæ‰¹æ¬¡", batches.len());
        let start_time = Instant::now();

        // å¹¶å‘å¤„ç†æ¯ä¸ªæ‰¹æ¬¡
        let decompressed_futures: Vec<_> = batches
            .into_iter()
            .map(|batch| {
                let batch_id = batch.batch_id;
                let batch_size = batch.len();
                task::spawn_blocking(move || {
                    debug!("âš™ï¸  å¤„ç†æ‰¹æ¬¡{}: {} ä¸ªå—", batch_id, batch_size);
                    let start = Instant::now();
                    
                    // åœ¨å½“å‰æ‰¹æ¬¡å†…å¹¶å‘è§£å‹
                    let decompressed: Result<Vec<_>, _> = batch.items
                        .into_par_iter()
                        .map(|block| {
                            Self::decompress_single_block_static(&block.compressed_data)
                        })
                        .collect();
                    
                    let batch_time = start.elapsed();
                    debug!("âœ… æ‰¹æ¬¡{} å®Œæˆ: {:.2}s, {:.0} å—/ç§’", 
                           batch_id, batch_time.as_secs_f64(), batch_size as f64 / batch_time.as_secs_f64());
                    
                    decompressed.map(|items| DataBatch::new(items, batch_id))
                })
            })
            .collect();

        // ç­‰å¾…æ‰€æœ‰æ‰¹æ¬¡å®Œæˆ
        let mut decompressed_batches = Vec::new();
        for future in decompressed_futures {
            let batch = future.await??;
            decompressed_batches.push(batch);
        }

        let total_time = start_time.elapsed();
        let total_blocks: usize = decompressed_batches.iter().map(|b| b.len()).sum();
        info!("ğŸ‰ æ‰¹å¤„ç†è§£å‹ç¼©å®Œæˆ: {} ä¸ªå—, è€—æ—¶ {:.2}s, ååé‡ {:.0} å—/ç§’", 
              total_blocks, total_time.as_secs_f64(), total_blocks as f64 / total_time.as_secs_f64());

        Ok(decompressed_batches)
    }

    /// è§£å‹ç¼©å•ä¸ªæ•°æ®å—ï¼ˆé™æ€æ–¹æ³•ï¼Œç”¨äºå¹¶å‘ï¼‰
    fn decompress_single_block_static(compressed_data: &[u8]) -> Result<Vec<u8>> {
        use flate2::read::GzDecoder;
        use std::io::Read;
        
        let mut decoder = GzDecoder::new(compressed_data);
        let mut decompressed = Vec::new();
        decoder.read_to_end(&mut decompressed)?;
        Ok(decompressed)
    }

    /// æ‰¹å¤„ç†å¹¶å‘è§£æ
    async fn parse_batches_concurrent(&self, batches: Vec<DataBatch<Vec<u8>>>) -> Result<Vec<ParsedFrame>> {
        info!("âš™ï¸  å¼€å§‹æ‰¹å¤„ç†å¹¶å‘è§£æ {} ä¸ªæ‰¹æ¬¡", batches.len());
        let start_time = Instant::now();

        // å¹¶å‘å¤„ç†æ¯ä¸ªæ‰¹æ¬¡
        let parse_futures: Vec<_> = batches
            .into_iter()
            .map(|batch| {
                let dbc_parser = self.dbc_parser.clone();
                let batch_id = batch.batch_id;
                let batch_size = batch.len();
                
                task::spawn_blocking(move || {
                    debug!("ğŸ” è§£ææ‰¹æ¬¡{}: {} ä¸ªæ•°æ®å—", batch_id, batch_size);
                    let start = Instant::now();
                    
                    // åœ¨å½“å‰æ‰¹æ¬¡å†…å¹¶å‘è§£æ
                    let parsed_results: Result<Vec<Vec<ParsedFrame>>, anyhow::Error> = batch.items
                        .into_par_iter()
                        .map(|decompressed_data| {
                            Self::parse_decompressed_data_fast(decompressed_data, dbc_parser.clone())
                        })
                        .collect();
                        
                    let parsed_frames: Result<Vec<ParsedFrame>, anyhow::Error> = match parsed_results {
                        Ok(frame_vecs) => {
                            let all_frames: Vec<ParsedFrame> = frame_vecs.into_iter().flatten().collect();
                            Ok(all_frames)
                        }
                        Err(e) => Err(e),
                    };
                    
                    let batch_time = start.elapsed();
                    match &parsed_frames {
                        Ok(frames) => {
                            debug!("âœ… æ‰¹æ¬¡{} è§£æå®Œæˆ: {} å¸§, {:.2}s, {:.0} å¸§/ç§’", 
                                   batch_id, frames.len(), batch_time.as_secs_f64(), 
                                   frames.len() as f64 / batch_time.as_secs_f64());
                        }
                        Err(e) => {
                            warn!("âŒ æ‰¹æ¬¡{} è§£æå¤±è´¥: {}", batch_id, e);
                        }
                    }
                    
                    parsed_frames
                })
            })
            .collect();

        // æ”¶é›†æ‰€æœ‰ç»“æœ
        let mut all_frames = Vec::new();
        for future in parse_futures {
            let frames = future.await??;
            all_frames.extend(frames);
        }

        let total_time = start_time.elapsed();
        info!("ğŸ‰ æ‰¹å¤„ç†è§£æå®Œæˆ: {} å¸§, è€—æ—¶ {:.2}s, ååé‡ {:.0} å¸§/ç§’", 
              all_frames.len(), total_time.as_secs_f64(), all_frames.len() as f64 / total_time.as_secs_f64());

        Ok(all_frames)
    }

    /// å¿«é€Ÿè§£æè§£å‹åçš„æ•°æ®ï¼ˆæ‰¹å¤„ç†ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
    fn parse_decompressed_data_fast(data: Vec<u8>, _dbc_parser: Arc<DbcParser>) -> Result<Vec<ParsedFrame>> {
        let mut frames = Vec::new();
        
        // ä½¿ç”¨å›ºå®šå¤§å°çš„æ‰¹æ¬¡å¤„ç†å¸§æ•°æ®
        let frame_size = 16; // å‡è®¾å¸§å¤§å°ä¸º16å­—èŠ‚
        let chunk_size = 1024; // 1KB å—
        
        // åˆ†å—å¹¶å‘å¤„ç†
        let chunks: Vec<_> = data.chunks(chunk_size).collect();
        let parallel_frames: Result<Vec<_>, _> = chunks
            .into_par_iter()
            .map(|chunk| {
                Self::parse_chunk_to_frames_fast(chunk, frame_size)
            })
            .collect();

        let chunk_frames = parallel_frames?;
        for mut chunk_frame_vec in chunk_frames {
            frames.append(&mut chunk_frame_vec);
        }

        Ok(frames)
    }

    /// å¿«é€Ÿè§£ææ•°æ®å—ä¸ºå¸§ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
    fn parse_chunk_to_frames_fast(chunk: &[u8], frame_size: usize) -> Result<Vec<ParsedFrame>> {
        let mut frames = Vec::new();
        let mut offset = 0;
        
        // é¢„åˆ†é…å®¹é‡ä»¥å‡å°‘å†…å­˜åˆ†é…
        let estimated_frames = chunk.len() / frame_size;
        frames.reserve(estimated_frames);
        
        while offset + frame_size <= chunk.len() {
            // å¿«é€Ÿè§£æå¸§ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            let frame = ParsedFrame {
                timestamp: u64::from_le_bytes([
                    chunk[offset], chunk[offset + 1], chunk[offset + 2], chunk[offset + 3],
                    chunk[offset + 4], chunk[offset + 5], chunk[offset + 6], chunk[offset + 7],
                ]),
                can_id: u32::from_le_bytes([
                    chunk[offset + 8], chunk[offset + 9], 
                    chunk[offset + 10], chunk[offset + 11]
                ]),
                data: chunk[offset + 12..offset + frame_size].to_vec(),
                signals: std::collections::HashMap::new(), // ç®€åŒ–å¤„ç†
            };
            frames.push(frame);
            offset += frame_size;
        }
        
        Ok(frames)
    }

    /// è·å–é…ç½®ä¿¡æ¯
    pub fn get_config(&self) -> &BatchProcessConfig {
        &self.config
    }

    /// æ€§èƒ½ç»Ÿè®¡
    pub fn estimate_performance(&self, file_count: usize, avg_file_size_mb: f64) -> BatchPerformanceEstimate {
        let total_data_gb = file_count as f64 * avg_file_size_mb / 1024.0;
        
        // åŸºäºæ‰¹å¤„ç†å¹¶å‘çš„æ€§èƒ½ä¼°ç®—
        let estimated_throughput_files_per_sec = match avg_file_size_mb {
            size if size < 1.0 => 50.0,      // å°æ–‡ä»¶ï¼š50 æ–‡ä»¶/ç§’
            size if size < 5.0 => 25.0,      // ä¸­ç­‰æ–‡ä»¶ï¼š25 æ–‡ä»¶/ç§’  
            size if size < 15.0 => 15.0,     // å¤§æ–‡ä»¶ï¼š15 æ–‡ä»¶/ç§’
            _ => 8.0,                        // è¶…å¤§æ–‡ä»¶ï¼š8 æ–‡ä»¶/ç§’
        };
        
        let estimated_time_seconds = file_count as f64 / estimated_throughput_files_per_sec;
        
        BatchPerformanceEstimate {
            total_files: file_count,
            total_data_gb,
            estimated_time_seconds,
            estimated_throughput_files_per_sec,
            batch_optimization_factor: 2.5, // æ‰¹å¤„ç†é¢„æœŸ2.5å€æå‡
        }
    }
}

/// æ‰¹å¤„ç†æ€§èƒ½ä¼°ç®—
#[derive(Debug, Clone)]
pub struct BatchPerformanceEstimate {
    pub total_files: usize,
    pub total_data_gb: f64,
    pub estimated_time_seconds: f64,
    pub estimated_throughput_files_per_sec: f64,
    pub batch_optimization_factor: f64,
}

impl BatchPerformanceEstimate {
    pub fn print_estimate(&self) {
        info!("ğŸ“Š æ‰¹å¤„ç†æ€§èƒ½é¢„ä¼°:");
        info!("  ğŸ“ æ€»æ–‡ä»¶æ•°: {}", self.total_files);
        info!("  ğŸ’¾ æ€»æ•°æ®é‡: {:.1} GB", self.total_data_gb);
        info!("  â±ï¸  é¢„ä¼°å¤„ç†æ—¶é—´: {:.1} åˆ†é’Ÿ", self.estimated_time_seconds / 60.0);
        info!("  ğŸš€ é¢„ä¼°ååé‡: {:.1} æ–‡ä»¶/ç§’", self.estimated_throughput_files_per_sec);
        info!("  ğŸ“ˆ æ‰¹å¤„ç†ä¼˜åŒ–å€æ•°: {:.1}x", self.batch_optimization_factor);
        
        if self.estimated_time_seconds <= 300.0 { // 5åˆ†é’Ÿ
            info!("  âœ… é¢„æœŸåœ¨5åˆ†é’Ÿå†…å®Œæˆï¼");
        } else {
            warn!("  âš ï¸  å¯èƒ½è¶…è¿‡5åˆ†é’Ÿç›®æ ‡ï¼Œå»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–");
        }
    }
}

/// æ‰¹å¤„ç†å¹¶å‘è§£æå™¨æ„å»ºå™¨
pub struct BatchConcurrentParserBuilder {
    memory_pool: Option<Arc<MemoryPool>>,
    dbc_parser: Option<Arc<DbcParser>>,
    file_reader: Option<CachedFileReader>,
    config: BatchProcessConfig,
}

impl BatchConcurrentParserBuilder {
    pub fn new() -> Self {
        Self {
            memory_pool: None,
            dbc_parser: None,
            file_reader: None,
            config: BatchProcessConfig::default(),
        }
    }

    pub fn memory_pool(mut self, pool: Arc<MemoryPool>) -> Self {
        self.memory_pool = Some(pool);
        self
    }

    pub fn dbc_parser(mut self, parser: Arc<DbcParser>) -> Self {
        self.dbc_parser = Some(parser);
        self
    }

    pub fn file_reader(mut self, reader: CachedFileReader) -> Self {
        self.file_reader = Some(reader);
        self
    }

    pub fn decompress_batch_size(mut self, size: usize) -> Self {
        self.config.decompress_batch_size = size;
        self
    }

    pub fn parse_batch_size(mut self, size: usize) -> Self {
        self.config.parse_batch_size = size;
        self
    }

    pub fn frame_batch_size(mut self, size: usize) -> Self {
        self.config.frame_batch_size = size;
        self
    }

    pub fn worker_threads(mut self, count: usize) -> Self {
        self.config.worker_threads = count;
        self
    }

    pub fn small_block_threshold(mut self, threshold: usize) -> Self {
        self.config.small_block_threshold = threshold;
        self
    }

    pub fn build(self) -> Result<BatchConcurrentParser> {
        Ok(BatchConcurrentParser::new(
            self.memory_pool.ok_or_else(|| anyhow!("Memory pool required"))?,
            self.dbc_parser.ok_or_else(|| anyhow!("DBC parser required"))?,
            self.file_reader,
            Some(self.config),
        ))
    }
}

impl Default for BatchConcurrentParserBuilder {
    fn default() -> Self {
        Self::new()
    }
}