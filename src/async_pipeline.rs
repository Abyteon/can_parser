use anyhow::Result;
use std::sync::Arc;
use std::path::PathBuf;
use tokio::sync::mpsc;
use std::sync::atomic::{AtomicUsize, Ordering};
use std::time::Instant;
use tracing::{info, warn, error};
use indicatif::{ProgressBar, ProgressStyle};

use crate::frame_parser::{FrameParser, ParsedFrame};
use crate::concurrent_frame_parser::ConcurrentFrameParser;
use crate::memory_pool::MemoryPool;

/// æµæ°´çº¿å·¥ä½œå•å…ƒ - ç®€å•æ¸…æ™°çš„æ•°æ®ç»“æ„
#[derive(Debug)]
pub struct PipelineTask {
    pub file_path: String,
    pub file_data: Option<Vec<u8>>,
    pub parsed_frames: Option<Vec<ParsedFrame>>,
    pub start_time: Instant,
}

impl PipelineTask {
    pub fn new(file_path: String) -> Self {
        Self {
            file_path,
            file_data: None,
            parsed_frames: None,
            start_time: Instant::now(),
        }
    }
}

/// æµæ°´çº¿é…ç½® - ä½¿ç”¨åˆç†é»˜è®¤å€¼
#[derive(Debug, Clone)]
pub struct PipelineConfig {
    pub io_workers: usize,      // I/Oå·¥ä½œçº¿ç¨‹æ•°
    pub cpu_workers: usize,     // CPUå·¥ä½œçº¿ç¨‹æ•°
    pub write_workers: usize,   // å†™å…¥å·¥ä½œçº¿ç¨‹æ•°
    pub channel_buffer: usize,  // é€šé“ç¼“å†²åŒºå¤§å°
}

impl Default for PipelineConfig {
    fn default() -> Self {
        let cpu_count = num_cpus::get();
        Self {
            io_workers: cpu_count * 2,     // I/Oå¯†é›†ï¼Œå¤šå¼€çº¿ç¨‹
            cpu_workers: cpu_count,        // CPUå¯†é›†ï¼ŒåŒ¹é…æ ¸å¿ƒæ•°
            write_workers: cpu_count / 2,  // å†™å…¥ç›¸å¯¹ç®€å•
            channel_buffer: 500,           // é€‚ä¸­çš„ç¼“å†²åŒº
        }
    }
}

/// å¼‚æ­¥æµæ°´çº¿å¤„ç†å™¨ - æ ¸å¿ƒæ¶æ„
pub struct AsyncPipeline {
    memory_pool: Arc<MemoryPool>,
    frame_parser: Arc<FrameParser>,
    concurrent_parser: Option<Arc<ConcurrentFrameParser>>,
    output_dir: PathBuf,
    config: PipelineConfig,
}

impl AsyncPipeline {
    pub fn new(
        memory_pool: Arc<MemoryPool>,
        frame_parser: Arc<FrameParser>,
        output_dir: PathBuf,
        config: Option<PipelineConfig>,
    ) -> Self {
        Self {
            memory_pool,
            frame_parser,
            concurrent_parser: None,
            output_dir,
            config: config.unwrap_or_default(),
        }
    }

    pub fn with_concurrent_parser(
        memory_pool: Arc<MemoryPool>,
        frame_parser: Arc<FrameParser>,
        concurrent_parser: Arc<ConcurrentFrameParser>,
        output_dir: PathBuf,
        config: Option<PipelineConfig>,
    ) -> Self {
        Self {
            memory_pool,
            frame_parser,
            concurrent_parser: Some(concurrent_parser),
            output_dir,
            config: config.unwrap_or_default(),
        }
    }

    /// è¿è¡Œå¼‚æ­¥æµæ°´çº¿ - ä¸»å…¥å£ç‚¹
    pub async fn process_files(&self, file_paths: Vec<String>) -> Result<()> {
        let start_time = Instant::now();
        let total_files = file_paths.len();
        
        info!("ğŸš€ å¯åŠ¨å¼‚æ­¥æµæ°´çº¿å¤„ç† {} ä¸ªæ–‡ä»¶", total_files);
        info!("âš™ï¸  é…ç½®: I/O={}, CPU={}, Write={}", 
            self.config.io_workers, 
            self.config.cpu_workers, 
            self.config.write_workers
        );

        // åˆ›å»ºæµæ°´çº¿é€šé“ - ä½¿ç”¨tokioçš„é«˜æ€§èƒ½mpsc
        let (io_tx, io_rx) = mpsc::channel::<PipelineTask>(self.config.channel_buffer);
        let (cpu_tx, cpu_rx) = mpsc::channel::<PipelineTask>(self.config.channel_buffer);
        let (write_tx, write_rx) = mpsc::channel::<PipelineTask>(self.config.channel_buffer);

        // åˆ›å»ºè¿›åº¦è·Ÿè¸ª
        let progress_bar = self.create_progress_bar(total_files);
        let completed_count = Arc::new(AtomicUsize::new(0));

        // å¯åŠ¨ä¸‰ä¸ªæµæ°´çº¿é˜¶æ®µ
        let io_handle = self.start_io_stage(file_paths, io_tx);
        let cpu_handle = self.start_cpu_stage(io_rx, cpu_tx);
        let write_handle = self.start_write_stage(cpu_rx, write_tx, completed_count.clone(), progress_bar.clone());
        let completion_handle = self.start_completion_stage(write_rx);

        // ç­‰å¾…æ‰€æœ‰é˜¶æ®µå®Œæˆ - ä½¿ç”¨tokio::join!ç®€åŒ–é”™è¯¯å¤„ç†
        let results = tokio::join!(io_handle, cpu_handle, write_handle, completion_handle);
        
        // æ£€æŸ¥æ¯ä¸ªé˜¶æ®µçš„ç»“æœ
        for (stage_name, result) in [
            ("I/O", &results.0),
            ("CPU", &results.1), 
            ("Write", &results.2),
            ("Completion", &results.3)
        ] {
            if let Err(e) = result {
                error!("{} é˜¶æ®µå¤±è´¥: {}", stage_name, e);
                return Err(anyhow::anyhow!("{} stage failed: {}", stage_name, e));
            }
        }

        let total_duration = start_time.elapsed();
        let throughput = total_files as f64 / total_duration.as_secs_f64();

        progress_bar.finish_with_message(format!(
            "ğŸ‰ æµæ°´çº¿å¤„ç†å®Œæˆ! {} æ–‡ä»¶ | {:.2}s | {:.0} æ–‡ä»¶/ç§’",
            total_files, total_duration.as_secs_f64(), throughput
        ));

        self.print_summary(total_files, total_duration, throughput);
        Ok(())
    }

    /// ç¬¬ä¸€é˜¶æ®µ: I/Oè¯»å– - åˆ©ç”¨tokioçš„å¼‚æ­¥I/O
    async fn start_io_stage(
        &self,
        file_paths: Vec<String>,
        io_tx: mpsc::Sender<PipelineTask>,
    ) -> Result<()> {
        info!("ğŸ“– å¯åŠ¨I/Oè¯»å–é˜¶æ®µ ({} ä¸ªå·¥ä½œçº¿ç¨‹)", self.config.io_workers);

        // ä½¿ç”¨tokio::sync::Semaphoreæ§åˆ¶å¹¶å‘æ•° - é¿å…é‡å¤é€ è½®å­
        let semaphore = Arc::new(tokio::sync::Semaphore::new(self.config.io_workers));
        
        // åˆ›å»ºä»»åŠ¡
        let mut tasks = Vec::new();
        for file_path in file_paths {
            let tx = io_tx.clone();
            let semaphore = semaphore.clone();
            
            let task = tokio::spawn(async move {
                let _permit = semaphore.acquire().await?;
                
                let mut pipeline_task = PipelineTask::new(file_path.clone());
                
                // ä½¿ç”¨tokioçš„å¼‚æ­¥æ–‡ä»¶è¯»å–
                match tokio::fs::read(&file_path).await {
                    Ok(data) => {
                        pipeline_task.file_data = Some(data);
                        tx.send(pipeline_task).await?;
                    },
                    Err(e) => {
                        error!("è¯»å–æ–‡ä»¶å¤±è´¥ {}: {}", file_path, e);
                    }
                }
                
                Result::<(), anyhow::Error>::Ok(())
            });
            
            tasks.push(task);
        }

        // ç­‰å¾…æ‰€æœ‰I/Oä»»åŠ¡å®Œæˆ
        for task in tasks {
            if let Err(e) = task.await? {
                warn!("I/Oä»»åŠ¡å¤±è´¥: {}", e);
            }
        }

        info!("âœ… I/Oè¯»å–é˜¶æ®µå®Œæˆ");
        Ok(())
    }

    /// ç¬¬äºŒé˜¶æ®µ: CPUå¤„ç† - åˆ©ç”¨rayonçš„å¹¶è¡Œè®¡ç®—
    async fn start_cpu_stage(
        &self,
        mut io_rx: mpsc::Receiver<PipelineTask>,
        cpu_tx: mpsc::Sender<PipelineTask>,
    ) -> Result<()> {
        info!("âš™ï¸  å¯åŠ¨CPUå¤„ç†é˜¶æ®µ ({} ä¸ªå·¥ä½œçº¿ç¨‹)", self.config.cpu_workers);
        
        // ä½¿ç”¨rayonçš„çº¿ç¨‹æ± è¿›è¡ŒCPUå¯†é›†å‹è®¡ç®—
        let semaphore = Arc::new(tokio::sync::Semaphore::new(self.config.cpu_workers));
        
        while let Some(mut task) = io_rx.recv().await {
            let tx = cpu_tx.clone();
            let semaphore = semaphore.clone();
            
            tokio::spawn(async move {
                let _permit = semaphore.acquire().await?;
                
                if let Some(file_data) = task.file_data.take() {
                    // ä½¿ç”¨tokio::task::spawn_blockingåœ¨ä¸“ç”¨çº¿ç¨‹æ± ä¸­è¿è¡ŒCPUå¯†é›†å‹ä»»åŠ¡
                    let parsed_result = tokio::task::spawn_blocking(move || {
                        Self::parse_data_parallel(&file_data)
                    }).await;
                    
                    match parsed_result {
                        Ok(Ok(frames)) => {
                            task.parsed_frames = Some(frames);
                            let _ = tx.send(task).await;
                        },
                        Ok(Err(e)) => {
                            error!("è§£ææ•°æ®å¤±è´¥ {}: {}", task.file_path, e);
                        },
                        Err(e) => {
                            error!("å¤„ç†ä»»åŠ¡è¢«å–æ¶ˆ {}: {}", task.file_path, e);
                        }
                    }
                }
                
                Result::<(), anyhow::Error>::Ok(())
            });
        }

        info!("âœ… CPUå¤„ç†é˜¶æ®µå®Œæˆ");
        Ok(())
    }

    /// ç¬¬ä¸‰é˜¶æ®µ: ç»“æœå†™å…¥ - å¼‚æ­¥å†™å…¥ä¼˜åŒ–
    async fn start_write_stage(
        &self,
        mut cpu_rx: mpsc::Receiver<PipelineTask>,
        write_tx: mpsc::Sender<PipelineTask>,
        completed_count: Arc<AtomicUsize>,
        progress_bar: ProgressBar,
    ) -> Result<()> {
        info!("ğŸ’¾ å¯åŠ¨å†™å…¥é˜¶æ®µ ({} ä¸ªå·¥ä½œçº¿ç¨‹)", self.config.write_workers);
        
        let output_dir = self.output_dir.clone();
        let semaphore = Arc::new(tokio::sync::Semaphore::new(self.config.write_workers));
        
        while let Some(task) = cpu_rx.recv().await {
            let tx = write_tx.clone();
            let output_dir = output_dir.clone();
            let semaphore = semaphore.clone();
            let completed_count = completed_count.clone();
            let progress_bar = progress_bar.clone();
            
            tokio::spawn(async move {
                let _permit = semaphore.acquire().await?;
                
                if let Some(frames) = &task.parsed_frames {
                    let output_path = output_dir.join(format!(
                        "{}.json",
                        std::path::Path::new(&task.file_path)
                            .file_stem()
                            .unwrap()
                            .to_string_lossy()
                    ));
                    
                    // ä½¿ç”¨tokio::task::spawn_blockingè¿›è¡ŒJSONåºåˆ—åŒ–
                    let json_result = tokio::task::spawn_blocking({
                        let frames = frames.clone();
                        move || serde_json::to_string_pretty(&frames)
                    }).await;
                    
                    match json_result {
                        Ok(Ok(json_data)) => {
                            // å¼‚æ­¥å†™å…¥æ–‡ä»¶
                            if let Err(e) = tokio::fs::write(&output_path, json_data).await {
                                error!("å†™å…¥æ–‡ä»¶å¤±è´¥ {:?}: {}", output_path, e);
                            } else {
                                let count = completed_count.fetch_add(1, Ordering::Relaxed) + 1;
                                progress_bar.set_position(count as u64);
                                let _ = tx.send(task).await;
                            }
                        },
                        Ok(Err(e)) => {
                            error!("JSONåºåˆ—åŒ–å¤±è´¥ {}: {}", task.file_path, e);
                        },
                        Err(e) => {
                            error!("åºåˆ—åŒ–ä»»åŠ¡è¢«å–æ¶ˆ {}: {}", task.file_path, e);
                        }
                    }
                }
                
                Result::<(), anyhow::Error>::Ok(())
            });
        }

        info!("âœ… å†™å…¥é˜¶æ®µå®Œæˆ");
        Ok(())
    }

    /// å®Œæˆé˜¶æ®µ: æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
    async fn start_completion_stage(
        &self,
        mut write_rx: mpsc::Receiver<PipelineTask>,
    ) -> Result<()> {
        let mut completed_files = 0;
        let mut total_processing_time = 0.0;
        
        while let Some(task) = write_rx.recv().await {
            completed_files += 1;
            total_processing_time += task.start_time.elapsed().as_secs_f64();
            
            // æ¯100ä¸ªæ–‡ä»¶æŠ¥å‘Šä¸€æ¬¡ç»Ÿè®¡
            if completed_files % 100 == 0 {
                let avg_time = total_processing_time / completed_files as f64;
                info!("ğŸ“Š å·²å®Œæˆ {} ä¸ªæ–‡ä»¶ï¼Œå¹³å‡å¤„ç†æ—¶é—´: {:.3}s", completed_files, avg_time);
            }
        }
        
        info!("ğŸ“Š æµæ°´çº¿ç»Ÿè®¡: å…±å®Œæˆ {} ä¸ªæ–‡ä»¶", completed_files);
        Ok(())
    }

    /// å¹¶è¡Œæ•°æ®è§£æ - åˆ©ç”¨rayonçš„å¹¶è¡Œè¿­ä»£å™¨
    fn parse_data_parallel(data: &[u8]) -> Result<Vec<ParsedFrame>> {
        use rayon::prelude::*;
        
        let chunk_size = 64 * 1024; // 64KBå—å¤§å°
        let chunks: Vec<_> = data.chunks(chunk_size).collect();
        
        // ä½¿ç”¨rayonçš„å¹¶è¡Œè¿­ä»£å™¨ - é¿å…æ‰‹åŠ¨ç®¡ç†çº¿ç¨‹
        let parallel_results: Result<Vec<Vec<ParsedFrame>>, _> = chunks
            .into_par_iter()
            .enumerate()
            .map(|(chunk_idx, chunk)| {
                Self::parse_chunk(chunk, chunk_idx)
            })
            .collect();
        
        match parallel_results {
            Ok(chunk_results) => {
                // é«˜æ•ˆåˆå¹¶ç»“æœ
                let total_frames: usize = chunk_results.iter().map(|frames| frames.len()).sum();
                let mut all_frames = Vec::with_capacity(total_frames);
                
                for mut chunk_frames in chunk_results {
                    all_frames.append(&mut chunk_frames);
                }
                
                Ok(all_frames)
            },
            Err(e) => Err(e)
        }
    }

    /// è§£æå•ä¸ªæ•°æ®å—
    fn parse_chunk(chunk: &[u8], chunk_idx: usize) -> Result<Vec<ParsedFrame>> {
        let mut frames = Vec::new();
        let mut offset = 0;
        let base_timestamp = (chunk_idx * 1000) as u64;
        
        while offset + 16 <= chunk.len() {
            let frame = ParsedFrame {
                timestamp: base_timestamp + offset as u64,
                can_id: u32::from_le_bytes([
                    chunk[offset], 
                    chunk[offset + 1], 
                    chunk[offset + 2], 
                    chunk[offset + 3]
                ]),
                data: chunk[offset + 4..offset + 12].to_vec(),
                signals: std::collections::HashMap::new(),
            };
            frames.push(frame);
            offset += 16;
        }
        
        Ok(frames)
    }

    /// åˆ›å»ºè¿›åº¦æ¡ - ä½¿ç”¨indicatifåº“
    fn create_progress_bar(&self, total: usize) -> ProgressBar {
        let pb = ProgressBar::new(total as u64);
        pb.set_style(
            ProgressStyle::default_bar()
                .template("{spinner:.green} [{elapsed_precise}] [{bar:40.cyan/blue}] {pos}/{len} ({eta}) {msg}")
                .unwrap()
                .progress_chars("â–ˆâ–‰â–Šâ–‹â–Œâ–â–â–  "),
        );
        pb
    }

    /// æ‰“å°æ€»ç»“æŠ¥å‘Š
    fn print_summary(&self, _total_files: usize, duration: std::time::Duration, throughput: f64) {
        info!("ğŸ“Š === å¼‚æ­¥æµæ°´çº¿å¤„ç†å®Œæˆ ===");
        info!("â±ï¸  æ€»è€—æ—¶: {:.2} ç§’", duration.as_secs_f64());
        info!("ğŸ”¥ å¹³å‡ååé‡: {:.0} æ–‡ä»¶/ç§’", throughput);
        info!("ğŸ’¾ å³°å€¼å†…å­˜ä½¿ç”¨: é¢„ä¼° ~{}GB", self.estimate_memory_usage_gb());

        if duration.as_secs() <= 300 {
            info!("ğŸ¯ ç›®æ ‡è¾¾æˆ! åœ¨ {:.2}s å†…å®Œæˆå¤„ç† (ç›®æ ‡: 300s)", duration.as_secs_f64());
        } else {
            warn!("âš ï¸ æœªè¾¾åˆ°5åˆ†é’Ÿç›®æ ‡ï¼Œè€—æ—¶ {:.2}s", duration.as_secs_f64());
        }
    }

    /// ä¼°ç®—å†…å­˜ä½¿ç”¨
    fn estimate_memory_usage_gb(&self) -> f64 {
        // ç®€åŒ–çš„å†…å­˜ä½¿ç”¨ä¼°ç®—
        let base_memory = 2.0; // åŸºç¡€å†…å­˜ä½¿ç”¨
        let pipeline_memory = (self.config.channel_buffer * 3 * 16) as f64 / (1024.0 * 1024.0 * 1024.0); // æµæ°´çº¿ç¼“å†²åŒº
        base_memory + pipeline_memory
    }
}

/// ä¾¿æ·çš„æ„å»ºå™¨æ¨¡å¼ - æä¾›æ¸…æ™°çš„API
pub struct AsyncPipelineBuilder {
    memory_pool: Option<Arc<MemoryPool>>,
    frame_parser: Option<Arc<FrameParser>>,
    output_dir: Option<PathBuf>,
    config: PipelineConfig,
}

impl AsyncPipelineBuilder {
    pub fn new() -> Self {
        Self {
            memory_pool: None,
            frame_parser: None,
            output_dir: None,
            config: PipelineConfig::default(),
        }
    }

    pub fn memory_pool(mut self, pool: Arc<MemoryPool>) -> Self {
        self.memory_pool = Some(pool);
        self
    }

    pub fn frame_parser(mut self, parser: Arc<FrameParser>) -> Self {
        self.frame_parser = Some(parser);
        self
    }

    pub fn output_dir(mut self, dir: PathBuf) -> Self {
        self.output_dir = Some(dir);
        self
    }

    pub fn io_workers(mut self, count: usize) -> Self {
        self.config.io_workers = count;
        self
    }

    pub fn cpu_workers(mut self, count: usize) -> Self {
        self.config.cpu_workers = count;
        self
    }

    pub fn write_workers(mut self, count: usize) -> Self {
        self.config.write_workers = count;
        self
    }

    pub fn channel_buffer(mut self, size: usize) -> Self {
        self.config.channel_buffer = size;
        self
    }

    pub fn build(self) -> Result<AsyncPipeline> {
        Ok(AsyncPipeline::new(
            self.memory_pool.ok_or_else(|| anyhow::anyhow!("Memory pool is required"))?,
            self.frame_parser.ok_or_else(|| anyhow::anyhow!("Frame parser is required"))?,
            self.output_dir.ok_or_else(|| anyhow::anyhow!("Output directory is required"))?,
            Some(self.config),
        ))
    }
}